{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712550e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rajes\\OneDrive\\Documents\\Python Scripts\\lib\\site-packages\\keras\\losses.py:2664: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Bidirectional,SimpleRNN,TimeDistributed, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0586a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "#input_text = [\n",
    " #   \"quick brown fox jumps\",\n",
    "  #  \"brown fox jumps over\",\n",
    "   # \"fox jumps over the\",\n",
    "    #\"jumps over the lazy\",\n",
    "    #\"over the lazy dog\"\n",
    "#]\n",
    "\n",
    "input_text = [\n",
    "    \"The sun is shining brightly\",\n",
    "    \"shining brightly in the blue\",\n",
    "    \"brightly in the blue sky\",\n",
    "    \"in the blue sky with\",\n",
    "    \"the blue sky with few\",\n",
    "    \"blue sky with few fluffy\",\n",
    "    \"sky with few fluffy clouds\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2cda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 13\n"
     ]
    }
   ],
   "source": [
    "# Tokenize input text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(input_text)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649d009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input text to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc259fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded input sequences: [[ 1 10 11  8  5]\n",
      " [ 8  5  6  1  2]\n",
      " [ 5  6  1  2  3]\n",
      " [ 6  1  2  3  4]\n",
      " [ 1  2  3  4  7]\n",
      " [ 2  3  4  7  9]\n",
      " [ 3  4  7  9 12]]\n"
     ]
    }
   ],
   "source": [
    "# Pad input sequences\n",
    "max_len = max(len(seq) for seq in input_sequences)\n",
    "padded_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='post')\n",
    "print(\"Padded input sequences:\", padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21392596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rajes\\OneDrive\\Documents\\Python Scripts\\lib\\site-packages\\keras\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Bi-RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=10, input_length=max_len-1),\n",
    "    Bidirectional(SimpleRNN(64, return_sequences=True)),\n",
    "    Bidirectional(SimpleRNN(64, return_sequences=True)),\n",
    "    TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f81760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rajes\\OneDrive\\Documents\\Python Scripts\\lib\\site-packages\\keras\\optimizers\\__init__.py:300: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 10)             130       \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 4, 128)           9600      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 4, 128)           24704     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 4, 13)            1677      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,111\n",
      "Trainable params: 36,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26747617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\rajes\\OneDrive\\Documents\\Python Scripts\\lib\\site-packages\\keras\\utils\\tf_utils.py:490: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rajes\\OneDrive\\Documents\\Python Scripts\\lib\\site-packages\\keras\\engine\\base_layer_utils.py:380: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5684 - accuracy: 0.1071\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.5248 - accuracy: 0.2143\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.4807 - accuracy: 0.2857\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4352 - accuracy: 0.4286\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3873 - accuracy: 0.5714\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3363 - accuracy: 0.6429\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2815 - accuracy: 0.6429\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2226 - accuracy: 0.6786\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.1591 - accuracy: 0.6786\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0910 - accuracy: 0.6786\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0186 - accuracy: 0.6786\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9424 - accuracy: 0.6786\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8631 - accuracy: 0.6786\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7816 - accuracy: 0.6786\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6982 - accuracy: 0.6786\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6130 - accuracy: 0.7143\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5253 - accuracy: 0.7143\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4346 - accuracy: 0.7143\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3407 - accuracy: 0.7143\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2441 - accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1459 - accuracy: 0.7857\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0480 - accuracy: 0.8571\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9523 - accuracy: 0.8929\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8603 - accuracy: 0.8929\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7735 - accuracy: 0.9643\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6924 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6172 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5475 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4832 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4239 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3696 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3202 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2758 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2363 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2016 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1715 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1457 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1238 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1053 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0898 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0769 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0662 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0573 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0499 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0386 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0251 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bf03dad030>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "X_data = padded_sequences[:, :-1]  # Input data (remove last word from each sequence)\n",
    "y_data = padded_sequences[:, 1:]   # Output data (remove first word from each sequence)\n",
    "model.fit(X_data, y_data, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71db763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences: ['The sun is shining brightly', 'shining brightly in the blue', 'brightly in the blue sky', 'in the blue sky with', 'the blue sky with few', 'blue sky with few fluffy', 'sky with few fluffy clouds']\n",
      "Padded input sequences: [[ 1 10 11  8  5]\n",
      " [ 8  5  6  1  2]\n",
      " [ 5  6  1  2  3]\n",
      " [ 6  1  2  3  4]\n",
      " [ 1  2  3  4  7]\n",
      " [ 2  3  4  7  9]\n",
      " [ 3  4  7  9 12]]\n",
      "Vocabulary size: 13\n",
      "Index-word mapping: {1: 'the', 2: 'blue', 3: 'sky', 4: 'with', 5: 'brightly', 6: 'in', 7: 'few', 8: 'shining', 9: 'fluffy', 10: 'sun', 11: 'is', 12: 'clouds'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 10)             130       \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 4, 128)           9600      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 4, 128)           24704     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 4, 13)            1677      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,111\n",
      "Trainable params: 36,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print input sequences and padded input sequences\n",
    "print(\"Input sequences:\", input_text)\n",
    "print(\"Padded input sequences:\", padded_sequences)\n",
    "\n",
    "# Verify vocabulary size and index-word mapping\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "print(\"Index-word mapping:\", tokenizer.index_word)\n",
    "\n",
    "# Inspect the model's architecture\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03095d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate next word prediction\n",
    "def predict_next_word(input_text):\n",
    "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_input_seq = pad_sequences(input_seq, maxlen=max_len-1, padding='post')\n",
    "    predicted_probs = model.predict(padded_input_seq)\n",
    "    predicted_index = np.argmax(predicted_probs[0][-1])\n",
    "    predicted_word = tokenizer.index_word.get(predicted_index, \"<Unknown>\")\n",
    "    return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54249d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Input: The sun is shining brightly, Predicted next word: clouds\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Input: shining brightly in the blue, Predicted next word: sky\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Input: brightly in the blue sky, Predicted next word: with\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Input: in the blue sky with, Predicted next word: few\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "Input: the blue sky with few, Predicted next word: fluffy\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Input: blue sky with few fluffy, Predicted next word: clouds\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Input: sky with few fluffy clouds, Predicted next word: clouds\n"
     ]
    }
   ],
   "source": [
    "# Generate next word predictions\n",
    "for text in input_text:\n",
    "    predicted_word = predict_next_word(text)\n",
    "    print(f\"Input: {text}, Predicted next word: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c26ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
