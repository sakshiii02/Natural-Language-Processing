{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62082651",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\n",
    "    \"The sun is shining brightly\",\n",
    "    \"shining brightly in the blue\",\n",
    "    \"brightly in the blue sky\",\n",
    "    \"in the blue sky with\",\n",
    "    \"the blue sky with few\",\n",
    "    \"blue sky with few fluffy\",\n",
    "    \"sky with few fluffy clouds\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize input text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(input_text)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input text to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af73829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad input sequences\n",
    "max_len = max(len(seq) for seq in input_sequences)\n",
    "padded_sequences = pad_sequences(input_sequences, maxlen=max_len,padding='post')\n",
    "print(\"Padded input sequences:\", padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=10, input_length=max_len-1),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b7f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "\n",
    "# Sample input text\n",
    "input_text = [\n",
    "    \"The quick brown fox jumps\",\n",
    "    \"brown fox jumps over\",\n",
    "    \"fox jumps over the\",\n",
    "    \"jumps over the lazy\",\n",
    "    \"over the lazy dog\"\n",
    "]\n",
    "\n",
    "# Tokenize input text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(input_text)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "\n",
    "# Convert input text to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(input_text)\n",
    "\n",
    "# Pad input sequences\n",
    "max_len = max(len(seq) for seq in input_sequences)\n",
    "padded_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='post')\n",
    "print(\"Padded input sequences:\", padded_sequences)\n",
    "\n",
    "# Define Bi-LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=10, input_length=max_len-1),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "X_data = padded_sequences[:, :-1]  # Input data (remove last word from each sequence)\n",
    "y_data = padded_sequences[:, 1:]   # Output data (remove first word from each sequence)\n",
    "model.fit(X_data, y_data, epochs=300, verbose=1)\n",
    "\n",
    "# Function to generate next word prediction\n",
    "def predict_next_word(input_text):\n",
    "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
    "    padded_input_seq = pad_sequences(input_seq, maxlen=max_len-1, padding='post')\n",
    "    predicted_probs = model.predict(padded_input_seq)\n",
    "    predicted_index = np.argmax(predicted_probs[0][-1])\n",
    "    predicted_word = tokenizer.index_word.get(predicted_index, \"<Unknown>\")\n",
    "    return predicted_word\n",
    "\n",
    "# Generate next word predictions\n",
    "for text in input_text:\n",
    "    predicted_word = predict_next_word(text)\n",
    "    print(f\"Input: {text}, Predicted next word: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54439e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
